 python3 main.py
2025-10-20 17:43:13.352915: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-10-20 17:43:13.406260: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
✓ Directory ensured: dataset/
✓ Directory ensured: model/
✓ Directory ensured: result/
Phase 1: Initializing ISAC System (CPU-heavy init)...
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1760996597.310778   16339 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 92981 MB memory:  -> device: 0, name: NVIDIA H100 NVL, pci bus id: 0000:43:00.0, compute capability: 9.0
Using TR 38.811 DenseUrban model (NTN).
I0000 00:00:1760996601.140669   16339 cuda_solvers.cc:175] Creating GpuSolver handles for stream 0xa39bb50
Phase 2/3: Generating multi-satellite dataset (GPU-friendly ops where possible)...
Generated 100/3000 multi-sat samples
Generated 200/3000 multi-sat samples
Generated 300/3000 multi-sat samples
Generated 400/3000 multi-sat samples
Generated 500/3000 multi-sat samples
Generated 600/3000 multi-sat samples
Generated 700/3000 multi-sat samples
Generated 800/3000 multi-sat samples
Generated 900/3000 multi-sat samples
Generated 1000/3000 multi-sat samples
Generated 1100/3000 multi-sat samples
Generated 1200/3000 multi-sat samples
Generated 1300/3000 multi-sat samples
Generated 1400/3000 multi-sat samples
Generated 1500/3000 multi-sat samples
Generated 1600/3000 multi-sat samples
Generated 1700/3000 multi-sat samples
Generated 1800/3000 multi-sat samples
Generated 1900/3000 multi-sat samples
Generated 2000/3000 multi-sat samples
Generated 2100/3000 multi-sat samples
Generated 2200/3000 multi-sat samples
Generated 2300/3000 multi-sat samples
Generated 2400/3000 multi-sat samples
Generated 2500/3000 multi-sat samples
Generated 2600/3000 multi-sat samples
Generated 2700/3000 multi-sat samples
Generated 2800/3000 multi-sat samples
Generated 2900/3000 multi-sat samples
Generated 3000/3000 multi-sat samples
Saving dataset to dataset/dataset_samples1500_sats4.pkl...
✓ Dataset saved to disk

=== DATA VALIDATION ===
Benign samples: 1500
Attack samples: 1500
Attack samples with emitter locations: 1500
Power ratio (attack/benign): 1.1460

Phase 4: Extracting features (GPU)...
2025-10-20 18:28:52.541729: I external/local_xla/xla/service/service.cc:163] XLA service 0x748d623f7a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-10-20 18:28:52.541765: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA H100 NVL, Compute Capability 9.0
2025-10-20 18:28:52.569971: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 90701
I0000 00:00:1760999332.882103   16339 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-10-20 18:29:08.077147: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.

Phase 5: Training dual-input CNN (H100 Optimized)...
Epoch 1/30
2025-10-20 18:29:17.436240: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:62] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. model/dropout/dropout/random_uniform/RandomUniform
37/37 [==============================] - ETA: 0s - loss: 0.8139 - accuracy: 0.7660 - auc: 0.8342
Epoch 1: val_accuracy improved from -inf to 0.52083, saving model to model/best_model.keras
37/37 [==============================] - 13s 345ms/step - loss: 0.8139 - accuracy: 0.7660 - auc: 0.8342 - val_loss: 1.0753 - val_accuracy: 0.5208 - val_auc: 0.7682
Epoch 2/30
37/37 [==============================] - ETA: 0s - loss: 0.7199 - accuracy: 0.8032 - auc: 0.8770
Epoch 2: val_accuracy did not improve from 0.52083
37/37 [==============================] - 0s 4ms/step - loss: 0.7199 - accuracy: 0.8032 - auc: 0.8770 - val_loss: 0.9987 - val_accuracy: 0.5208 - val_auc: 0.9138
Epoch 3/30
37/37 [==============================] - ETA: 0s - loss: 0.6662 - accuracy: 0.8260 - auc: 0.8984
Epoch 3: val_accuracy improved from 0.52083 to 0.56771, saving model to model/best_model.keras
37/37 [==============================] - 0s 8ms/step - loss: 0.6662 - accuracy: 0.8260 - auc: 0.8984 - val_loss: 0.9116 - val_accuracy: 0.5677 - val_auc: 0.9652
Epoch 4/30
37/37 [==============================] - ETA: 0s - loss: 0.5873 - accuracy: 0.8530 - auc: 0.9295
Epoch 4: val_accuracy did not improve from 0.56771
37/37 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.8530 - auc: 0.9295 - val_loss: 1.3345 - val_accuracy: 0.4792 - val_auc: 0.9556
Epoch 5/30
37/37 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.9307 - auc: 0.9736
Epoch 5: val_accuracy did not improve from 0.56771
37/37 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.9307 - auc: 0.9736 - val_loss: 2.7023 - val_accuracy: 0.4792 - val_auc: 0.8856
Epoch 6/30
37/37 [==============================] - ETA: 0s - loss: 0.4109 - accuracy: 0.9295 - auc: 0.9756
Epoch 6: val_accuracy did not improve from 0.56771
37/37 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.9295 - auc: 0.9756 - val_loss: 1.7805 - val_accuracy: 0.4792 - val_auc: 0.9731
Epoch 7/30
37/37 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.9464 - auc: 0.9829
Epoch 7: val_accuracy did not improve from 0.56771
37/37 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.9464 - auc: 0.9829 - val_loss: 2.9002 - val_accuracy: 0.4792 - val_auc: 0.8071
Epoch 8/30
37/37 [==============================] - ETA: 0s - loss: 0.3336 - accuracy: 0.9535 - auc: 0.9873
Epoch 8: val_accuracy did not improve from 0.56771
37/37 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.9535 - auc: 0.9873 - val_loss: 2.8953 - val_accuracy: 0.4792 - val_auc: 0.7922
Epoch 9/30
37/37 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.9552 - auc: 0.9893
Epoch 9: val_accuracy did not improve from 0.56771
37/37 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.9552 - auc: 0.9893 - val_loss: 2.5384 - val_accuracy: 0.4792 - val_auc: 0.8710
Epoch 10/30
37/37 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.9616 - auc: 0.9900
Epoch 10: val_accuracy did not improve from 0.56771
37/37 [==============================] - 0s 4ms/step - loss: 0.2992 - accuracy: 0.9616 - auc: 0.9900 - val_loss: 1.8611 - val_accuracy: 0.4792 - val_auc: 0.9528
Epoch 11/30
37/37 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.9586 - auc: 0.9881
Epoch 11: val_accuracy did not improve from 0.56771
37/37 [==============================] - 0s 4ms/step - loss: 0.2992 - accuracy: 0.9586 - auc: 0.9881 - val_loss: 2.3857 - val_accuracy: 0.4792 - val_auc: 0.8917
Epoch 12/30
37/37 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.9599 - auc: 0.9911
Epoch 12: val_accuracy did not improve from 0.56771
37/37 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.9599 - auc: 0.9911 - val_loss: 2.4166 - val_accuracy: 0.4792 - val_auc: 0.8732
Epoch 13/30
37/37 [==============================] - ETA: 0s - loss: 0.2574 - accuracy: 0.9679 - auc: 0.9932
Epoch 13: val_accuracy did not improve from 0.56771
37/37 [==============================] - 0s 4ms/step - loss: 0.2574 - accuracy: 0.9679 - auc: 0.9932 - val_loss: 2.8280 - val_accuracy: 0.4792 - val_auc: 0.7961
Epoch 13: early stopping
Restoring model weights from the end of the best epoch: 3.

=== TRAIN SUMMARY ===
Best epoch: 6
Best val_auc: 0.9731
Final train_acc: 0.9679

Evaluating on test set (H100)...
Test Results → Loss: 0.9117 | Acc: 0.5667 | AUC: 0.9637

=== THRESHOLD TUNING ===
Default threshold (0.5) results:
  F1 score: 0.1720

Optimized threshold: 0.4602
  Best F1 score: 0.9078
  Precision at best threshold: 0.9242
  Recall at best threshold: 0.8920
  Improvement: 73.58%

=== GENERATING PAPER PLOTS ===

=== CONFUSION MATRIX ===
                Predicted
              Benign  Attack
Actual Benign   292      21
       Attack    32     255

=== CLASSIFICATION REPORT ===
              precision    recall  f1-score   support

      Benign       0.90      0.93      0.92       313
      Attack       0.92      0.89      0.91       287

    accuracy                           0.91       600
   macro avg       0.91      0.91      0.91       600
weighted avg       0.91      0.91      0.91       600

AUPRC (avg precision): 0.967
✓ ROC curve saved to result/1_roc_curve.pdf
✓ Precision-Recall curve saved to result/2_precision_recall_curve.pdf
✓ Confusion Matrix saved to result/3_confusion_matrix.pdf
✓ Training History saved to result/5_training_history.pdf
✓ Power Spectrum saved to result/6_power_spectrum.pdf
✓ F1 vs Threshold saved to result/7_f1_vs_threshold.pdf
✓ Spectrogram Examples saved to result/9_spectrogram_examples.pdf

=== PHASE 8: TDoA-BASED LOCALIZATION ===
Processing true positives...
/usr/local/lib/python3.12/dist-packages/numpy/fft/_pocketfft.py:70: ComplexWarning: Casting complex values to real discards the imaginary part
  r = pfi.execute(a, is_real, is_forward, fct)
  Sample 1801 | GT [-4653.9234153  26322.38797344] | EST [200000. 200000.] | Error=268415.99 m
  Sample 1817 | GT [ -6311.36342334 -25950.55469766] | EST [200000. 200000.] | Error=305970.64 m
  Sample 2505 | GT [108915.65574004 -43065.9466547 ] | EST [ -7992.95672119 200000.        ] | Error=269719.63 m

=== TDoA Localization Results ===
Median Error: 285521.62 m
Mean Error  : 278378.29 m
90th Perc.  : 362661.11 m
Total samples: 255
✓ Localization CDF saved to result/4_localization_cdf.pdf
✓ Localization Histogram saved to result/8_localization_histogram.pdf

============================================================
SIMULATION COMPLETE - SUMMARY
============================================================
Dataset: 3000 samples (1500 per class)
Model: Dual-Input CNN (saved to model/)
Results: All plots saved to result/
Best Threshold: 0.4602 (F1=0.9078)
Localization: Median Error = 285521.62 m, 90th = 362661.11 m
============================================================
root@d05388087b30:/workspace# ^C
root@d05388087b30:/workspace# clear