# Cross-Validation Guide

## ğŸ“Š Overview

5-Fold Stratified Cross-Validation Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ robust Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯ CNN detector Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù‡ Ø§Ø³Øª.

---

## âœ… Ú†Ø±Ø§ Cross-ValidationØŸ

### Ù…Ø²Ø§ÛŒØ§:
1. **Confidence Intervals:** Ø¨Ù‡ Ø¬Ø§ÛŒ ÛŒÚ© Ø¹Ø¯Ø¯ØŒ `mean Â± std` Ø¯Ø§Ø±ÛŒÙ…
2. **Robustness Check:** Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ model stable Ø§Ø³Øª
3. **No Lucky Split:** Ø§Ø«Ø¨Ø§Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ train/test split Ø®Ø§Øµ ÙˆØ§Ø¨Ø³ØªÙ‡ Ù†ÛŒØ³Øª
4. **Reviewer Friendly:** Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¯Ø± ML papers

### Example Output:
```
Before CV:  AUC = 0.99 (Ø´Ø§ÛŒØ¯ lucky split Ø¨ÙˆØ¯ØŸ)
After CV:   AUC = 0.99 Â± 0.01 (Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯!)
```

---

## ğŸ”„ Implementation Details

### Configuration:
- **Method:** Stratified K-Fold
- **K (folds):** 5
- **Dataset:** 10,000 samples
- **Train/Val per fold:** 8,000 / 2,000
- **Stratification:** Ø­ÙØ¸ Ù†Ø³Ø¨Øª 50/50 benign/attack

### Why 5 folds?
- âœ… Balance Ø¨ÛŒÙ† Ø§Ø¹ØªØ¨Ø§Ø± Ùˆ Ø²Ù…Ø§Ù†
- âœ… Ù‡Ø± fold = 2K test samples (Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ metrics)
- âœ… 5 Ã— 2 scenarios = 10 models total
- â±ï¸ Ø²Ù…Ø§Ù† Ù…Ø¹Ù‚ÙˆÙ„ (3-4 Ø³Ø§Ø¹Øª)

### Training per fold:
- **Architecture:** Ù‡Ù…Ø§Ù† CNN Ø§Ø² `main_detection_cnn.py`
- **Epochs:** Ø­Ø¯Ø§Ú©Ø«Ø± 100 Ø¨Ø§ Early Stopping
- **Batch size:** 512
- **Callbacks:** 
  - Early Stopping (patience=15)
  - ReduceLROnPlateau (patience=7)

---

## ğŸ“ Files

### Input:
- `dataset/dataset_scenario_a_*.pkl` (Scenario A)
- `dataset/dataset_scenario_b_*.pkl` (Scenario B)

### Output:
- `result/cross_validation_results.json` - Ù†ØªØ§ÛŒØ¬ Ú©Ø§Ù…Ù„
- `logs/cross_validation.log` - Ù„Ø§Ú¯ Ø§Ø¬Ø±Ø§

### Code:
- `run_cross_validation.py` - Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø§ØµÙ„ÛŒ

---

## ğŸš€ How to Run

### Manual Execution:
```bash
# Run in foreground (3-4 hours)
python3 run_cross_validation.py

# Run in background
nohup python3 run_cross_validation.py > logs/cross_validation.log 2>&1 &

# Check progress
tail -f logs/cross_validation.log

# Check if running
ps aux | grep run_cross_validation
```

### Check Results:
```bash
# View results
cat result/cross_validation_results.json

# Pretty print
python3 -c "import json; print(json.dumps(json.load(open('result/cross_validation_results.json')), indent=2))"
```

---

## ğŸ“Š Results Interpretation

### Output Structure:
```json
{
  "scenario_a": {
    "n_folds": 5,
    "fold_results": [ ... ],
    "aggregated": {
      "auc": {
        "mean": 0.9923,
        "std": 0.0045,
        "values": [0.99, 0.98, 1.0, 0.99, 0.99]
      },
      "precision": { ... },
      "recall": { ... },
      "f1": { ... }
    }
  },
  "scenario_b": { ... }
}
```

### Key Metrics:

**Mean (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†):**
- Ù†ØªÛŒØ¬Ù‡ average Ø§Ø² 5 fold
- Ø§ÛŒÙ† Ø¹Ø¯Ø¯ Ø±Ùˆ Ø¯Ø± paper report Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…

**Std (Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø±):**
- Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ consistency
- std Ú©ÙˆÚ†Ú© = stable model âœ…
- std Ø¨Ø²Ø±Ú¯ = unstable model âš ï¸

**Values:**
- Ù†ØªÛŒØ¬Ù‡ Ù‡Ø± fold Ø¨Ù‡ ØµÙˆØ±Øª Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
- Ø¨Ø±Ø§ÛŒ debugging ÛŒØ§ analysis Ø¹Ù…ÛŒÙ‚â€ŒØªØ±

---

## ğŸ“ How to Report in Paper

### In Results Section:

**Table Format:**
```
Method          Scenario A              Scenario B
              AUC         F1           AUC         F1
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SVM           0.63Â±0.02  0.68Â±0.03    0.60Â±0.03  0.70Â±0.02
CNN (ours)    0.99Â±0.01  0.94Â±0.02    0.98Â±0.02  0.40Â±0.05
```

**Text Format:**
> "We performed 5-fold stratified cross-validation to ensure robust 
> evaluation. Our CNN achieves AUC of 0.99Â±0.01 for Scenario A and 
> 0.98Â±0.02 for Scenario B, demonstrating consistent performance 
> across different data splits."

**Confidence Interval:**
```
95% CI for AUC:
mean Â± 1.96 Ã— std

Example:
AUC = 0.99 Â± 0.01
95% CI = [0.97, 1.01] â†’ [0.97, 1.0] (capped)
```

---

## âœ… What Good Results Look Like

### Scenario A (Ultra-Covert):

**Good:**
- Mean AUC: 0.95 - 1.0 âœ…
- Std: < 0.05 âœ…
- Ø§ÛŒÙ† Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ø¨Ø§ 10K dataØŒ CNN ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ‡

**Acceptable:**
- Mean AUC: 0.90 - 0.95
- Std: < 0.10
- Ù‡Ù…Ú†Ù†Ø§Ù† Ø®ÙˆØ¨ ÙˆÙ„ÛŒ variance Ø¨ÛŒØ´ØªØ±

**Poor:**
- Mean AUC: < 0.90 âš ï¸
- Std: > 0.10 âš ï¸
- Ù…Ù…Ú©Ù†Ù‡ overfitting ÛŒØ§ unstable training Ø¨Ø§Ø´Ù‡

### Scenario B (Relay):

**Good:**
- Mean AUC: 0.95 - 1.0 âœ…
- Std: < 0.05 âœ…

**Acceptable:**
- Mean AUC: 0.85 - 0.95
- Std: < 0.10

**Poor:**
- Mean AUC: < 0.85 âš ï¸
- Std: > 0.10 âš ï¸

---

## ğŸ” Troubleshooting

### Issue: High Variance (std > 0.10)

**Possible Causes:**
1. Dataset imbalance between folds
2. Model too sensitive to initialization
3. Training instability

**Solutions:**
- Check fold distribution
- Increase training epochs
- Adjust learning rate
- Add more regularization

### Issue: Low Mean AUC

**Possible Causes:**
1. Model architecture issues
2. Insufficient training
3. Data quality problems

**Solutions:**
- Review model architecture
- Increase epochs/patience
- Check dataset quality

### Issue: Process Killed

**Possible Causes:**
- Out of memory (GPU/RAM)
- Timeout

**Solutions:**
```bash
# Reduce batch size in code
# Check memory
nvidia-smi

# Check logs
tail -100 logs/cross_validation.log
```

---

## ğŸ“ˆ Comparison: Single Split vs Cross-Validation

### Before (Single Split):
```python
Train: 8000 samples (80%)
Test:  2000 samples (20%)

Result: AUC = 0.99
```

**Question:** Ø¢ÛŒØ§ Ø§ÛŒÙ† lucky split Ø¨ÙˆØ¯ØŸ ğŸ¤”

### After (5-Fold CV):
```python
Fold 1: Train 8K, Test 2K â†’ AUC = 0.99
Fold 2: Train 8K, Test 2K â†’ AUC = 0.98
Fold 3: Train 8K, Test 2K â†’ AUC = 1.00
Fold 4: Train 8K, Test 2K â†’ AUC = 0.99
Fold 5: Train 8K, Test 2K â†’ AUC = 0.99

Mean: 0.99 Â± 0.01
```

**Answer:** Ù†Ù‡! Ù†ØªØ§ÛŒØ¬ consistent Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯ Ù‡Ø³ØªÙ†Ø¯ âœ…

---

## ğŸ¯ Benefits for Your Paper

### 1. Scientific Rigor
- Cross-validation = best practice
- Reviewers expect this for ML papers
- Shows thoroughness

### 2. Confidence Intervals
- `AUC = 0.99 Â± 0.01` Ù‚ÙˆÛŒâ€ŒØªØ± Ø§Ø² `AUC = 0.99`
- Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ results robust Ù‡Ø³ØªÙ†Ø¯
- Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ statistical tests

### 3. Defense Against Reviewers
**Q:** "How do you know this isn't due to a lucky train/test split?"  
**A:** "We performed 5-fold CV. Results are consistent across all folds (std=0.01)."

**Q:** "What if you had chosen a different random seed?"  
**A:** "Cross-validation averages over multiple splits, reducing dependency on random seed."

### 4. Comparison Fairness
- Ù‡Ù…Ù‡ methods (CNN, baselines) Ø¨Ø§ÛŒØ¯ CV Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯
- Ø§Ù…Ø§ Ø¨Ø±Ø§ÛŒ speedØŒ ÙÙ‚Ø· CNN Ø±Ùˆ CV Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
- Baselines Ø¨Ø§ single split Ù‚Ø§Ø¨Ù„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡Ø³ØªÙ†Ø¯ (conservative approach)

---

## ğŸ“š References

### Papers Using 5-Fold CV:
1. Standard practice Ø¯Ø± medical ML
2. Common Ø¯Ø± security/intrusion detection
3. Expected Ø¯Ø± high-stakes applications

### Why Not 10-Fold?
- 5-fold: faster, sufficient for 10K samples
- 10-fold: more accurate but 2x slower
- For your case: 5-fold is perfect balance

### Why Stratified?
- Ø­ÙØ¸ class distribution (50/50) Ø¯Ø± Ù‡Ø± fold
- Important Ø¨Ø±Ø§ÛŒ imbalanced ÛŒØ§ balanced datasets
- Ensures fair evaluation

---

## â±ï¸ Time Estimates

### Per Fold:
- Training: ~10-15 min (Ø¨Ø§ early stopping)
- Evaluation: ~1 min
- Total: ~15-20 min per fold

### Complete Run:
- Scenario A: 5 folds Ã— 15-20 min = 1.5-2 hours
- Scenario B: 5 folds Ã— 15-20 min = 1.5-2 hours
- **Total: 3-4 hours**

### GPU Usage:
- H100 NVL: highly efficient
- Memory: ~5-6 GB per model
- Utilization: 80-100%

---

## âœ… Checklist

Before claiming CV results:
- [ ] All 5 folds completed successfully
- [ ] No folds failed or crashed
- [ ] Results file exists and is valid JSON
- [ ] Mean and std calculated correctly
- [ ] Std is reasonable (< 0.10)
- [ ] Results match expectations

For paper:
- [ ] Report mean Â± std for all metrics
- [ ] Include CV methodology in paper
- [ ] Compare with single-split results
- [ ] Discuss consistency across folds
- [ ] Mention stratification

---

## ğŸ“ Summary

âœ… **Ú†Ø±Ø§ CV Ù…Ù‡Ù…Ù‡:**
- Robust evaluation
- Confidence intervals
- Reviewer expectations
- Scientific rigor

âœ… **Ú†ÛŒ Ø§Ù†ØªØ¸Ø§Ø± Ø¯Ø§Ø±ÛŒÙ…:**
- Scenario A: AUC â‰ˆ 0.99 Â± 0.01
- Scenario B: AUC â‰ˆ 0.98 Â± 0.02
- Low variance â†’ stable model

âœ… **Ú†Ø·ÙˆØ± report Ú©Ù†ÛŒÙ…:**
- Table Ø¨Ø§ mean Â± std
- Text Ø¨Ø§ confidence intervals
- Discussion of consistency

---

**Cross-validation ØªØ­Ù‚ÛŒÙ‚ Ø´Ù…Ø§ Ø±Ùˆ Ø§Ø² Ø®ÙˆØ¨ Ø¨Ù‡ Ø¹Ø§Ù„ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ù‡! ğŸš€**

*Last Updated: 2025-11-11*

